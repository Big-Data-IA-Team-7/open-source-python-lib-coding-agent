{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cc34ba7-63cc-4a18-ae21-f449e07a7ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "SNOWFLAKE_ACCOUNT = \"\"\n",
    "SNOWFLAKE_USERNAME = \"\"\n",
    "SNOWFLAKE_PASSWORD = \"\"\n",
    "SNOWFLAKE_DATABASE = \"\"\n",
    "SNOWFLAKE_SCHEMA = \"\"\n",
    "SNOWFLAKE_WAREHOUSE = \"\"\n",
    "SNOWFLAKE_ROLE = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6794359d-a396-4481-b316-dcdcc21cb99d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634dffd6-e438-403d-bbdf-2ec373ee9d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3629480b-8ba2-4651-9224-c7debe42959b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24e28c0-e661-4472-a623-e70a918334c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd0bf69-031f-4291-9cd2-26a26157ea6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b3d2dba-e22e-4f06-9d95-2606c9cded21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snowflake://:@//?warehouse=&role=\n"
     ]
    }
   ],
   "source": [
    "print(f\"snowflake://{SNOWFLAKE_USERNAME}:{SNOWFLAKE_PASSWORD}@{SNOWFLAKE_ACCOUNT}/{SNOWFLAKE_DATABASE}/{SNOWFLAKE_SCHEMA}?warehouse={SNOWFLAKE_WAREHOUSE}&role={SNOWFLAKE_ROLE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6998a0-2f6e-4ca3-8bc9-e1b145e6457d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209bece9-c769-4832-9f55-f41012a8fb36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1c0661-b758-4835-bb9c-c9564bcfc2a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0563e371-3da3-4532-8ef3-3afb766d7843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858552e6-b52f-4170-b06c-14a51d4a90de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d694dc6f-5df6-46de-8652-04de5d7e4ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6a9e050a-6b1b-44bd-9abc-ac66c7f0ee71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a052186-8aec-4ea8-ad54-933ce8b49528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22003e4e-79c4-4da0-b5e6-c377d456e87c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "59c3ba23-67b8-42a9-a78e-5f1d5743dc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "# Create a SQLDatabase instance\n",
    "db = SQLDatabase.from_uri(f\"snowflake://{SNOWFLAKE_USERNAME}:{SNOWFLAKE_PASSWORD}@{SNOWFLAKE_ACCOUNT}/{SNOWFLAKE_DATABASE}/{SNOWFLAKE_SCHEMA}?warehouse={SNOWFLAKE_WAREHOUSE}&role={SNOWFLAKE_ROLE}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43cfcb6-ee99-4b72-9f76-3b65a00b64c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8175a35-ffe9-4084-b619-620328dd541a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bfad92-002f-4218-b33e-a704e7450864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "db131c61-2060-453d-9b3b-03d8292ee4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44658393-b56a-46f6-983f-5a67c11c8655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "69d0cb3c-e4d9-4db8-952d-dd1e4f700fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY =  ''\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4\",api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077a37ba-41f1-4791-9723-c8e689b72f87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f917745c-4bdc-4cfe-a369-3f7d25d5f6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d45f88-e8fb-4dd8-88cc-76937cc82247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc4f5d9-ad63-4159-88ee-45772be29083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20519e6d-3715-4593-b619-6199ac8ce5ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a2fd5a3f-f4d1-4846-984b-fe60d68b7be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SQL agent toolkit\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)  # Replace `llm` with your language model instance\n",
    "\n",
    "# Get the tools for the agent\n",
    "tools = toolkit.get_tools()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a033adfa-15c3-4b2f-8e6d-4b1244514679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0159d21a-b644-4314-8c22-4f46358ed1ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "571096ad-c546-4f5c-8cb0-040b387b0768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[(18201, \\'langgraph/docs/docs/tutorials/introduction.ipynb\\', \\'introduction.ipynb\\', \\'tutorials\\', 2, \\'%%capture --no-stderr\\\\n%pip install -U langgraph langsmith langchain_anthropic\\', \\'# ðŸš€ LangGraph Quick Start\\\\n\\\\nIn this tutorial, we will build a support chatbot in LangGraph that can:\\\\n\\\\nâœ… **Answer common questions** by searching the web  \\\\nâœ… **Maintain conversation state** across calls  \\\\nâœ… **Route complex queries** to a human for review  \\\\nâœ… **Use custom state** to control its...\\', \\'Markdown not found\\', datetime.datetime(2024, 11, 29, 10, 33, 8, 205000)), (18202, \\'langgraph/docs/docs/tutorials/introduction.ipynb\\', \\'introduction.ipynb\\', \\'tutorials\\', 3, \\'import getpass\\\\nimport os\\\\n\\\\n\\\\ndef _set_env(var: str):\\\\n    if not os.environ.get(var):\\\\n        os.environ[var] = getpass.getpass(f\"{var}: \")\\\\n\\\\n\\\\n_set_env(\"ANTHROPIC_API_KEY\")\\', \\'Markdown not found\\', \\'Set up LangSmith for LangGraph development\\\\n\\\\n        Sign up for LangSmith to quickly spot issues and improve the performance of your LangGraph projects. LangSmith lets you use trace data to debug, test, and monitor your LLM apps built with LangGraph â€” read more about how to get started...\\', datetime.datetime(2024, 11, 29, 10, 33, 8, 205000)), (18203, \\'langgraph/docs/docs/tutorials/introduction.ipynb\\', \\'introduction.ipynb\\', \\'tutorials\\', 6, \\'from typing import Annotated\\\\n\\\\nfrom typing_extensions import TypedDict\\\\n\\\\nfrom langgraph.graph import StateGraph, START, END\\\\nfrom langgraph.graph.message import add_messages\\\\n\\\\n\\\\nclass State(TypedDict):\\\\n    # Messages have the type \"list\". The `add_messages` function\\\\n    # in the annotation defines...\\', \\'Set up LangSmith for LangGraph development\\\\n\\\\n        Sign up for LangSmith to quickly spot issues and improve the performance of your LangGraph projects. LangSmith lets you use trace data to debug, test, and monitor your LLM apps built with LangGraph â€” read more about how to get started...\\', \\'Our graph can now handle two key tasks:\\\\n\\\\n1. Each `node` can receive the current `State` as input and output an update to the state.\\\\n2. Updates to `messages` will be appended to the existing list rather than overwriting it, thanks to the prebuilt...\\', datetime.datetime(2024, 11, 29, 10, 33, 8, 205000)), (18204, \\'langgraph/docs/docs/tutorials/introduction.ipynb\\', \\'introduction.ipynb\\', \\'tutorials\\', 8, \\'from langchain_anthropic import ChatAnthropic\\\\n\\\\nllm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\\\\n\\\\n\\\\ndef chatbot(state: State):\\\\n    return {\"messages\": [llm.invoke(state[\"messages\"])]}\\\\n\\\\n\\\\n# The first argument is the unique node name\\\\n# The second argument is the function or object that will be...\\', \\'Our graph can now handle two key tasks:\\\\n\\\\n1. Each `node` can receive the current `State` as input and output an update to the state.\\\\n2. Updates to `messages` will be appended to the existing list rather than overwriting it, thanks to the prebuilt...\\', \\'**Notice** how the `chatbot` node function takes the current `State` as input and returns a dictionary containing an updated `messages` list under the key \"messages\". This is the basic pattern for all LangGraph node functions.\\\\n\\\\nThe `add_messages` function in our `State` will append the llm\\\\\\'s...\\', datetime.datetime(2024, 11, 29, 10, 33, 8, 205000)), (18205, \\'langgraph/docs/docs/tutorials/introduction.ipynb\\', \\'introduction.ipynb\\', \\'tutorials\\', 10, \\'graph_builder.add_edge(START, \"chatbot\")\\', \\'**Notice** how the `chatbot` node function takes the current `State` as input and returns a dictionary containing an updated `messages` list under the key \"messages\". This is the basic pattern for all LangGraph node functions.\\\\n\\\\nThe `add_messages` function in our `State` will append the llm\\\\\\'s...\\', \\'Similarly, set a `finish` point. This instructs the graph **\"any time this node is run, you can exit.\"**\\\\n\\', datetime.datetime(2024, 11, 29, 10, 33, 8, 205000)), (18206, \\'langgraph/docs/docs/tutorials/introduction.ipynb\\', \\'introduction.ipynb\\', \\'tutorials\\', 12, \\'graph_builder.add_edge(\"chatbot\", END)\\', \\'Similarly, set a `finish` point. This instructs the graph **\"any time this node is run, you can exit.\"**\\\\n\\', \\'Finally, we\\\\\\'ll want to be able to run our graph. To do so, call \"`compile()`\" on the graph builder. This creates a \"`CompiledGraph`\" we can use invoke on our state.\\\\n\\', datetime.datetime(2024, 11, 29, 10, 33, 8, 205000)), (18207, \\'langgraph/docs/docs/tutorials/introduction.ipynb\\', \\'introduction.ipynb\\', \\'tutorials\\', 14, \\'graph = graph_builder.compile()\\', \\'Finally, we\\\\\\'ll want to be able to run our graph. To do so, call \"`compile()`\" on the graph builder. This creates a \"`CompiledGraph`\" we can use invoke on our state.\\\\n\\', \\'You can visualize the graph using the `get_graph` method and one of the \"draw\" methods, like `draw_ascii` or `draw_png`. The `draw` methods each require additional dependencies.\\\\n\\', datetime.datetime(2024, 11, 29, 10, 33, 8, 205000)), (18208, \\'langgraph/docs/docs/tutorials/introduction.ipynb\\', \\'introduction.ipynb\\', \\'tutorials\\', 16, \\'from IPython.display import Image, display\\\\n\\\\ntry:\\\\n    display(Image(graph.get_graph().draw_mermaid_png()))\\\\nexcept Exception:\\\\n    # This requires some extra dependencies and is optional\\\\n    pass\\', \\'You can visualize the graph using the `get_graph` method and one of the \"draw\" methods, like `draw_ascii` or `draw_png`. The `draw` methods each require additional dependencies.\\\\n\\', \\'Now let\\\\\\'s run the chatbot! \\\\n\\\\n**Tip:** You can exit the chat loop at any time by typing \"quit\", \"exit\", or \"q\".\\\\n\\', datetime.datetime(2024, 11, 29, 10, 33, 8, 205000)), (18209, \\'langgraph/docs/docs/tutorials/introduction.ipynb\\', \\'introduction.ipynb\\', \\'tutorials\\', 18, \\'def stream_graph_updates(user_input: str):\\\\n    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\\\\n        for value in event.values():\\\\n            print(\"Assistant:\", value[\"messages\"][-1].content)\\\\n\\\\n\\\\nwhile True:\\\\n    try:\\\\n        user_input = input(\"User: \")\\\\n        if...\\', \\'Now let\\\\\\'s run the chatbot! \\\\n\\\\n**Tip:** You can exit the chat loop at any time by typing \"quit\", \"exit\", or \"q\".\\\\n\\', \"**Congratulations!** You\\'ve built your first chatbot using LangGraph. This bot can engage in basic conversation by taking user input and generating responses using an LLM. You can inspect a [LangSmith Trace](https://smith.langchain.com/public/7527e308-9502-4894-b347-f34385740d5a/r) for the call...\", datetime.datetime(2024, 11, 29, 10, 33, 8, 205000)), (18210, \\'langgraph/docs/docs/tutorials/introduction.ipynb\\', \\'introduction.ipynb\\', \\'tutorials\\', 21, \\'%%capture --no-stderr\\\\n%pip install -U tavily-python langchain_community\\', \"**Congratulations!** You\\'ve built your first chatbot using LangGraph. This bot can engage in basic conversation by taking user input and generating responses using an LLM. You can inspect a [LangSmith Trace](https://smith.langchain.com/public/7527e308-9502-4894-b347-f34385740d5a/r) for the call...\", \\'Markdown not found\\', datetime.datetime(2024, 11, 29, 10, 33, 8, 205000))]'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.run(\"SELECT * FROM EDW.github_notebook_cells LIMIT 10;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d473c1d-5452-45f0-a1f8-f424c05174e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "045c34c0-3765-4cd7-8072-c27056f8302c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['github_classes',\n",
       " 'github_consolidated_notebooks',\n",
       " 'github_functions',\n",
       " 'github_global_statements',\n",
       " 'github_markdown_docs',\n",
       " 'github_markdown_sections',\n",
       " 'github_notebook_cells',\n",
       " 'userdetails']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.get_usable_table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "58bcd79c-63fd-4b41-93c3-f2ecf4b2b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import SQLDatabase\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.agents.agent_types import AgentType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04840873-4453-40f3-8786-646d26ac60ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9042899-87f5-48ca-ad91-82b2b72dbab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "906bed45-43c4-411a-9993-71ea1a61aa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt = \"You are a SQL expert. Given a user's question, create a syntactically correct SQL query to retrieve the necessary data from the database. The database contains various tables with various functions, classes and methods. Go over the code column in each table. If the user asks specfic functions/classes/code retreive the full code to the user\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a06147-48b1-41a2-aea3-ebfea7e4af5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23affefa-7205-4ad7-bcd0-25ba90b0a106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7dc97245-00ed-4ba5-b99b-aed9276b1fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = create_sql_agent(\n",
    "    llm=llm,\n",
    "    toolkit=SQLDatabaseToolkit(db=db, llm=llm),\n",
    "    verbose=True,\n",
    "    agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfa9d41-d00d-4d1b-bf46-c0da52fc310d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a3bd053d-28a8-41b5-9d7e-fa24321f4feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = create_sql_agent(\n",
    "    llm=llm,\n",
    "    toolkit=SQLDatabaseToolkit(db=db, llm=llm),\n",
    "    verbose=True,\n",
    "    agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "    state_modifier=custom_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c185d6a2-4918-4957-a057-2d1798b93a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c55ff6a-408d-4679-aaf0-a55e897e785a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940cba13-cfa7-4eb2-a6bb-918ee6b6cab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d805eb-26f3-4520-8a9f-40a034444956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd779c5-ea81-43cf-a815-79b4a0797013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ebbc7d-ed47-43e5-b20a-f71d82a0b40e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8365f6-0e9d-4e41-8560-7ee83121cb6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c14511a3-29d9-4758-a858-ef105d99dfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SQL Agent Executor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_list_tables` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mgithub_classes, github_consolidated_notebooks, github_functions, github_global_statements, github_markdown_docs, github_markdown_sections, github_notebook_cells, userdetails\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_schema` with `{'table_names': 'github_classes'}`\n",
      "responded: The relevant table for this query seems to be the 'github_classes'. Let's look at its schema.\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m\n",
      "CREATE TABLE github_classes (\n",
      "\tclass_id DECIMAL(38, 0) NOT NULL IDENTITY(1,1), \n",
      "\tclass_name VARCHAR(255), \n",
      "\tfilepath VARCHAR(500), \n",
      "\tfilename VARCHAR(255), \n",
      "\tcode VARCHAR(16777216), \n",
      "\tcreated_at TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP(), \n",
      "\tCONSTRAINT \"SYS_CONSTRAINT_f3d96bba-efc2-4255-b54d-c0d108041274\" PRIMARY KEY (class_id)\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from github_classes table:\n",
      "class_id\tclass_name\tfilepath\tfilename\tcode\tcreated_at\n",
      "3401\tAddableUpdatesDict\tlanggraph/libs/langgraph/langgraph/pregel/io.py\tio.py\tclass AddableUpdatesDict:\n",
      "def __add__(self, other: dict[str, Any]) -> 'AddableUpdatesDict':\n",
      "    retu\t2024-11-29 10:33:05.432000\n",
      "3402\tAddableValuesDict\tlanggraph/libs/langgraph/langgraph/pregel/io.py\tio.py\tclass AddableValuesDict:\n",
      "def __add__(self, other: dict[str, Any]) -> 'AddableValuesDict':\n",
      "    return\t2024-11-29 10:33:05.432000\n",
      "3403\tAnalyst\tlanggraph/libs/langgraph/tests/test_pregel.py\ttest_pregel.py\tclass Analyst:\n",
      "@property\n",
      "def persona(self) -> str:\n",
      "    return f'Name: {self.name}\\nRole: {self.role}\t2024-11-29 10:33:05.432000\n",
      "*/\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `sql_db_query` with `{'query': \"SELECT class_name, filepath, filename, code FROM github_classes WHERE class_name = 'StateGraph' LIMIT 10\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[('StateGraph', 'langgraph/libs/langgraph/langgraph/graph/state.py', 'state.py', 'class StateGraph:\\ndef __init__(self, state_schema: Optional[Type[Any]]=None, config_schema: Optional[Type[Any]]=None, *, input: Optional[Type[Any]]=None, output: Optional[Type[Any]]=None) -> None:\\n    super().__init__()\\n    if state_schema is None:\\n        if input is None or output is None:\\n   ...')]\u001b[0m\u001b[32;1m\u001b[1;3mHere is the full code for the 'StateGraph' class:\n",
      "\n",
      "```python\n",
      "class StateGraph:\n",
      "    def __init__(self, state_schema: Optional[Type[Any]]=None, config_schema: Optional[Type[Any]]=None, *, input: Optional[Type[Any]]=None, output: Optional[Type[Any]]=None) -> None:\n",
      "        super().__init__()\n",
      "        if state_schema is None:\n",
      "            if input is None or output is None:\n",
      "   ...\n",
      "```\n",
      "\n",
      "This was found in the file 'state.py' located at 'langgraph/libs/langgraph/langgraph/graph/state.py'.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Here is the full code for the 'StateGraph' class:\\n\\n```python\\nclass StateGraph:\\n    def __init__(self, state_schema: Optional[Type[Any]]=None, config_schema: Optional[Type[Any]]=None, *, input: Optional[Type[Any]]=None, output: Optional[Type[Any]]=None) -> None:\\n        super().__init__()\\n        if state_schema is None:\\n            if input is None or output is None:\\n   ...\\n```\\n\\nThis was found in the file 'state.py' located at 'langgraph/libs/langgraph/langgraph/graph/state.py'.\""
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\n",
    "    \"Give full code to build class StateGraph\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcf3e5a-a89d-4d5f-a27e-a72795496f64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
